{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "cwd":"${fileDirname}"
        },
        {
            "name": "Python: setup_dataset_nuscenes_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_test.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0,1,2,3"
            },
            "args": [
                "--nuscenes_data_root_dirpath", "/data/zfy_data/nuscenes/nuscenes_origin",
                "--nuscenes_data_derived_dirpath", "/data/zfy_data/nuscenes/nuscenes-derived-test",
                "--n_scenes_to_process", "150",
                "--n_forward_frames_to_reproject", "24",
                "--n_backward_frames_to_reproject", "24",
                "--n_thread", "1",
                "--start_scene","5"
                //"--paths_only"
            ]
        },
        {
            "name": "Python: setup_dataset_nuscenes_radarnet_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_radarnet_test.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0,1,2,3"
            },
            "args": [
                "--restore_path", "checkpoints/Radarnet/model-195000.pth",
                "--patch_size", "900", "288",
                "--input_channels_image", "3",
                "--input_channels_depth", "3",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "radarnetv1", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "128", "128",
                "--n_neurons_encoder_depth", "32", "64", "128", "128", "128",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "128", "64", "32", "16",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--run_evaluation",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "100.0",
                "--paths_only"
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: run_radarnet_on_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/run_radarnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                "--restore_path", "checkpoints/Radarnet/model-195000.pth",
                "--image_path","testing/nuscenes/nuscenes_test_image.txt",
                "--radar_path","testing/nuscenes/nuscenes_test_radar.txt",
                "--patch_size", "900", "288",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "radarnetv1", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "128", "128",
                "--n_neurons_encoder_depth", "32", "64", "128", "128", "128",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "128", "64", "32", "16",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--output_dirpath","/data/zfy_data/nuscenes/nuscenes_derived_test",
                "--save_outputs",
                "--keep_input_filenames",
                "--verbose",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "100.0",
                "--response_thr", "0.5"
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: run_fusionnet_nuscenes_res_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/run_fusionnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                "--restore_path", "trained_fusionnet_scale_bias_res/0707111555__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_add_output_type_scale_and_bias_res_total_epoch_400--wo_align_svby_intp_multilidar_scale_bias_inv_GPU_7/model-40000.pth",
                "--depths_in_use","mono_depth","rela_depth","inv",
                "--image_path", "testing/nuscenes/nuscenes_test_image.txt",
                "--depth_path", "testing/nuscenes/nuscenes_test_radar_image.txt",
                "--mono_depth_path","testing/nuscenes/nuscenes_test_dany_metric_predicted.txt",
                "--rela_depth_path","testing/nuscenes/nuscenes_test_dany_rela_predicted.txt",
                //"--response_path", "testing/nuscenes/nuscenes_test_response_predicted.txt",
                "--ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                "--input_channels_image", "3",
                "--input_channels_depth", "1",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                "--output_type","scale_and_bias_res",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                "--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                "--fusion_type", "add",
                "--fusion_layers","0","1",
                // "--guidance","RGI_CBAM_concat",
                // "--guidance_layers","3","4","5","6",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--output_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test_debug/virl_6-29/res-wo-radarnet-4k",
                //"--output_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test_debug/virl_5-8/fusionnet_predicted_sub_wdenselwlr_1.0_wmultilidar_2.0_baseline_radar_image_192500_80",
                "--keep_input_filenames",
                "--verbose",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--save_outputs",
                //"--save_dnzs_path"
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: run_fusionnet_nuscenes_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/run_fusionnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                "--restore_path", "/home/zfy/radar-camera-fusion-depth/trained_fusionnet_refine_fulldata/0621232951__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_SVFF_add_guidance_RGI_CBAM_concat_output_type_metric_depth_total_epoch_349--wo_align_svby_intp_multilidar_from26w_GPU_4/model-520000.pth",
                //------------------for virsualization-----------------------------------
                // "--image_path", "visl/path_txt/nuscenes/nuscenes_test_mini_dany_metric_radar_aligned.txt",
                // "--depth_path", "visl/path_txt/nuscenes/nuscenes_test_mini_radar_image.txt",
                // //"--response_path", "visl/path_txt/nuscenes/nuscenes_test_mini_response_predicted.txt",
                // "--ground_truth_path", "visl/path_txt/nuscenes/nuscenes_test_mini_lidar.txt",
                //------------------mono as image-----------------------------------
                "--image_path", "testing/nuscenes/nuscenes_test_dany_metric_predicted.txt",
                "--depth_path", "testing/nuscenes/nuscenes_test_radar_image.txt",
                //"--response_path", "testing/nuscenes/nuscenes_test_response_predicted.txt",
                "--ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                //------------------without RadarNet-----------------------------------
                // "--image_path", "testing/nuscenes/nuscenes_test_image.txt",
                // "--depth_path", "testing/nuscenes/nuscenes_test_radar_image.txt",
                // //"--response_path", "testing/nuscenes/nuscenes_test_response_predicted.txt",
                // "--ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                //------------------with RadarNet---------------------------------------
                // "--image_path", "testing/nuscenes/nuscenes_test_image.txt",
                // "--depth_path", "testing/nuscenes/nuscenes_test_depth_predicted.txt",
                //"--response_path", "testing/nuscenes/nuscenes_test_response_predicted.txt",
                // "--ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                //-----------------------------------------------------------------------
                "--input_channels_image", "1",
                "--input_channels_depth", "1",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                //"--n_filters_encoder_depth", "32", "64", "128", "256", "256", "256",
                "--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                "--fusion_type", "SVFF_add",
                "--guidance","RGI_CBAM_concat",
                "--guidance_layers","3","4","5","6",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--output_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test_debug/virl_6-10/mono-refine",
                //"--output_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test_debug/virl_5-8/fusionnet_predicted_sub_wdenselwlr_1.0_wmultilidar_2.0_baseline_radar_image_192500_80",
                "--keep_input_filenames",
                "--verbose",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--save_outputs",
                //"--save_dnzs_path"
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: run_structralnet_nuscenes_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/run_structralnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                "--restore_path", "/home/zfy/radar-camera-fusion-depth/trained_structralnet/0523140608_depth_loss_l1_w_depth_loss_0.0_w_grad_loss_0.0_w_ssim_loss_0.0_w_smoothness_0.0_w_perceptual_loss_1.0_multiscale_1_total_epoch_400_******_kd_on_dany_metric_with_perceptual_loss_GPU_4/model-195200.pth",
                "--image_path", "visl/path_txt/nuscenes/nuscenes_test_mini_image.txt",
                "--ground_truth_path", "visl/path_txt/nuscenes/nuscenes_test_mini_dany_metirc_predicted.txt",
                "--input_channels_image", "3",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "resnet18", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--output_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test_debug/structralnet-wgrad1_wssim0_wdepth1_multiscale4_sobel-1952000",
                "--keep_input_filenames",
                "--verbose",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--save_outputs",
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: setup_dataset_nuscenes",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_with_denseGT.py",
            "console": "integratedTerminal",
            "args": [
                "--nuscenes_data_root_dirpath", "/data/zfy_data/nuscenes/nuscenes_origin",
                "--nuscenes_data_derived_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived",
                "--n_scenes_to_process", "850",
                "--n_forward_frames_to_reproject", "80",
                "--n_backward_frames_to_reproject", "80",
                "--n_thread", "1",
                "--panoptic_seg_dir", "/data/zfy_data/nuscenes/nuscenes_derived/panoptic_segmentation_masks",
                "--paths_only",
                "--start_scene","0",
            ],
            "cwd": "${workspaceFolder}"
        },       
        {
            "name": "Python: setup_dataset_nuscenes_radar_images",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_radar_image.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                "--nuscenes_data_root_dirpath", "/data/zfy_data/nuscenes/nuscenes_origin",
                "--nuscenes_data_derived_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived",
                "--n_scenes_to_process", "850",
                "--n_forward_frames_to_reproject", "80",
                "--n_backward_frames_to_reproject", "80",
                "--n_thread", "1",
                "--paths_only",
                "--start_scene","0",
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: setup_dataset_nuscenes_radar_images_test",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_radar_image_test.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                "--nuscenes_data_root_dirpath", "/data/zfy_data/nuscenes/nuscenes_origin",
                "--nuscenes_data_derived_dirpath", "/data/zfy_data/nuscenes/nuscenes_derived_test",
                "--n_scenes_to_process", "850",
                "--n_forward_frames_to_reproject", "80",
                "--n_backward_frames_to_reproject", "80",
                "--n_thread", "1",
                //"--paths_only",
                "--start_scene","0",
            ],
            "cwd": "${workspaceFolder}"
        },
        {
            "name": "Python: Train FusionNet",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/train_fusionnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                //"--depths_in_use","",
                //"--radar_camera_fusionnet_restore_path","/home/zfy/radar-camera-fusion-depth/trained_fusionnet_ablation/0604172806__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_gated_radar_SVFF_transfer_type_decoder_guidance_RGI_CBAM_concat_layers_[3, 4, 5, 6]_total_epoch_400--------svby_kdondanyrelaparam_intp_multilidar_GPU_2/model-140000.pth",
                //"--structralnet_restore_path","trained_structralnet/0329160924_depth_loss_l1_w_depth_loss_1.0_w_grad_loss_1.0_w_ssim_loss_1.0_w_smoothness_0.0_multiscale_4_total_epoch_400_******_sobel_for_grad_ssimwin5_GPU_3/model-195200.pth",
                //"--transfer_type","encoder","decoder",
                //"--frozen_strategy","conv1","blocks2_image","blocks3_image",
                "--train_image_path", "training/nuscenes_sub/nuscenes_train_image.txt",
                //"--train_image_path", "training/nuscenes_sub/nuscenes_train_dany_metric_radar_lwlr.txt",
                "--train_depth_path", "training/nuscenes_sub/nuscenes_train_radar_image.txt",
                //"--train_response_path", "training/nuscenes_sub/nuscenes_train_dany_metric_radar_aligned.txt",
                "--train_ground_truth_path", "training/nuscenes_sub/nuscenes_train_ground_truth_interp.txt",
                "--train_lidar_map_path", "training/nuscenes_sub/nuscenes_train_lidar.txt",
                // "--val_image_path", "validation/nuscenes_sub/nuscenes_val_image.txt",
                // "--val_depth_path", "validation/nuscenes_sub/nuscenes_val_radar_image.txt",
                // "--val_response_path", "validation/nuscenes_sub/nuscenes_val_response_predicted.txt",
                // "--val_ground_truth_path", "validation/nuscenes_sub/nuscenes_val_lidar.txt",
                "--val_image_path", "testing/nuscenes/nuscenes_test_image.txt",
                //"--val_image_path", "testing/nuscenes/nuscenes_test_dany_metric_radar_lwlr.txt",
                "--val_depth_path", "testing/nuscenes/nuscenes_test_radar_image.txt",
                //"--val_response_path", "testing/nuscenes/nuscenes_test_dany_metric_radar_aligned.txt",
                "--val_ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                "--batch_size", "16",
                "--n_height", "448",
                "--n_width", "448",
                "--input_channels_image", "3",
                "--input_channels_depth", "1",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                //"--frozen_strategy","conv.weight","norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                "--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                //"--n_filters_encoder_depth", "32", "64", "128", "256", "256", "256",
                "--fusion_type", "SVFF_add",
                "--guidance","RGI_CBAM_concat",
                "--guidance_layers","3","4","5","6",
                "--decoder_type", "multiscale", "batch_norm",
                "--output_type","metric_depth",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--learning_rates", "1e-4","1e-5",
                "--learning_schedule", "64","114",
                "--loss_func", "l1",
                "--w_smoothness", "0.0",
                "--w_lidar_loss", "2.0",
                "--w_dense_loss","1.0",
                "--w_perceptual_loss","0.0",
                "--w_weight_decay", "0.0",
                "--loss_smoothness_kernel_size", "-1",
                "--outlier_removal_kernel_size", "7",
                "--outlier_removal_threshold", "1.5",
                "--ground_truth_dilation_kernel_size", "-1",
                "--augmentation_probabilities", "1.00",
                "--augmentation_schedule", "-1",
                "--augmentation_random_crop_type", "horizontal", "vertical",
                "--augmentation_random_brightness", "0.80", "1.20",
                "--augmentation_random_contrast", "0.80", "1.20",
                "--augmentation_random_saturation", "0.80", "1.20",
                "--augmentation_random_flip_type", "horizontal",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--checkpoint_dirpath", "/home/zfy/radar-camera-fusion-depth/checkpoints/Fusionnet",
                "--resultsave_dirpath", "trained_radar_camera_fusionnet_debug",
                "--n_step_per_checkpoint", "5",
                "--n_step_per_summary", "1",
                "--n_step_per_validation", "10",
                "--n_thread", "8",
                "--disc","debug",
                "--seed","355123027"
            ]
        },
        {
            "name": "Python: Train FusionNet res",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/train_fusionnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                //"--radar_camera_fusionnet_restore_path","/home/zfy/radar-camera-fusion-depth/trained_fusionnet/scale_bias_res/0628143203__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_add_output_type_scale_and_bias_res_total_epoch_300--wo_align_svby_intp_multilidar_scale_bias_res_w_radarnet_GPU_1/model-20000.pth",
                "--depths_in_use","mono_depth","rela_depth",
                "--train_image_path", "training/nuscenes/nuscenes_train_image.txt",
                "--train_depth_path", "training/nuscenes/nuscenes_train_output_depth.txt",
                "--train_mono_depth_path", "training/nuscenes/nuscenes_train_dany_metirc_predicted.txt",
                "--train_rela_depth_path", "training/nuscenes/nuscenes_train_dany_rela_predicted.txt",
                //"--train_response_path", "training/nuscenes/nuscenes_train_response_predicted.txt",
                "--train_ground_truth_path", "training/nuscenes/nuscenes_train_ground_truth_interp.txt",
                "--train_lidar_map_path", "training/nuscenes/nuscenes_train_lidar.txt",
                "--val_image_path", "testing/nuscenes/nuscenes_test_image.txt",
                "--val_depth_path", "testing/nuscenes/nuscenes_test_output_depth.txt",
                "--val_mono_depth_path", "testing/nuscenes/nuscenes_test_dany_metric_predicted.txt",
                "--val_rela_depth_path", "testing/nuscenes/nuscenes_test_dany_rela_predicted.txt",
                //"--val_response_path", "testing/nuscenes/nuscenes_test_output_response.txt",
                "--val_ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                "--batch_size", "16",
                "--n_height", "448",
                "--n_width", "448",
                // "--n_height", "224",
                // "--n_width", "400",
                "--input_channels_image", "3",
                "--input_channels_depth", "1",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                //"--frozen_strategy","conv.weight","norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", 
                "--n_filters_encoder_depth", "32", "64", "128", "256", "256", 
                //"--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                "--fusion_type", "attention",
                "--fusion_layers","3","4","5",
                "--guidance","RGI_CBAM_concat",
                "--guidance_layers","3","4","5",
                "--decoder_type", "multiscale", "batch_norm",
                "--output_type","scale_and_bias_res",
                "--dropout_prob","0.1",
                "--n_filters_decoder", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--learning_rates", "1e-4","1e-5",
                "--learning_schedule", "64","114",
                "--loss_func", "l1",
                "--w_smoothness", "0.0",
                "--w_lidar_loss", "2.0",
                "--w_dense_loss","1.0",
                "--w_perceptual_loss","0.0",
                "--w_weight_decay", "0.0",
                "--loss_smoothness_kernel_size", "-1",
                "--outlier_removal_kernel_size", "7",
                "--outlier_removal_threshold", "1.5",
                "--ground_truth_dilation_kernel_size", "-1",
                "--augmentation_probabilities", "1.00",
                "--augmentation_schedule", "-1",
                "--augmentation_random_crop_type", "horizontal", "vertical",
                "--augmentation_random_brightness", "0.80", "1.20",
                "--augmentation_random_contrast", "0.80", "1.20",
                "--augmentation_random_saturation", "0.80", "1.20",
                "--augmentation_random_flip_type", "horizontal",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--checkpoint_dirpath", "/home/zfy/radar-camera-fusion-depth/checkpoints/Fusionnet",
                "--resultsave_dirpath", "trained_radar_camera_fusionnet_debug",
                "--n_step_per_checkpoint", "1",
                "--n_step_per_summary", "10",
                "--n_step_per_validation", "10",
                "--n_thread", "8",
                "--disc","debug",
                "--seed","355123027"
            ]
        },
        {
            "name": "Python: Train RCMDNet res",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/RCMDNet/train_rcmdnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                //"--radar_camera_fusionnet_restore_path","/home/zfy/radar-camera-fusion-depth/trained_fusionnet/scale_bias_res/0628143203__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_add_output_type_scale_and_bias_res_total_epoch_300--wo_align_svby_intp_multilidar_scale_bias_res_w_radarnet_GPU_1/model-20000.pth",
                "--depths_in_use","mono_depth","rela_depth",
                "--train_image_path", "training/nuscenes/nuscenes_train_image.txt",
                "--train_radar_path", "training/nuscenes/nuscenes_train_output_depth.txt",
                "--train_mono_depth_path", "training/nuscenes/nuscenes_train_dany_metirc_predicted.txt",
                "--train_rela_depth_path", "training/nuscenes/nuscenes_train_dany_rela_predicted.txt",
                "--train_ground_truth_path", "training/nuscenes/nuscenes_train_ground_truth_interp.txt",
                "--train_lidar_map_path", "training/nuscenes/nuscenes_train_lidar.txt",
                "--val_image_path", "testing/nuscenes/nuscenes_test_image.txt",
                "--val_radar_path", "testing/nuscenes/nuscenes_test_output_depth.txt",
                "--val_mono_depth_path", "testing/nuscenes/nuscenes_test_dany_metric_predicted.txt",
                "--val_rela_depth_path", "testing/nuscenes/nuscenes_test_dany_rela_predicted.txt",
                "--val_ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                //-----------batch settings-------------------------
                "--batch_size", "16",
                "--patch_size","768","288",
                "--n_height", "448",
                "--n_width", "448",
                "--input_channels_image", "3",
                "--input_channels_depth", "1",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                //"--frozen_strategy","conv.weight","norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", 
                "--n_filters_encoder_depth", "32", "64", "128", "256", "256", 
                //"--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                "--fusion_type", "attention",
                "--fusion_layers","3","4","5",
                "--guidance","RGI_CBAM_concat",
                "--guidance_layers","3","4","5",
                "--decoder_type", "multiscale", "batch_norm",
                "--output_type","scale_and_bias_res",
                "--dropout_prob","0.1",
                "--n_filters_decoder", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--learning_rates", "1e-4","1e-5",
                "--learning_schedule", "64","114",
                "--loss_func", "l1",
                "--w_smoothness", "0.0",
                "--w_lidar_loss", "2.0",
                "--w_dense_loss","1.0",
                "--w_perceptual_loss","0.0",
                "--w_weight_decay", "0.0",
                "--loss_smoothness_kernel_size", "-1",
                "--outlier_removal_kernel_size", "7",
                "--outlier_removal_threshold", "1.5",
                "--ground_truth_dilation_kernel_size", "-1",
                "--augmentation_probabilities", "1.00",
                "--augmentation_schedule", "-1",
                "--augmentation_random_crop_type", "horizontal", "vertical",
                "--augmentation_random_brightness", "0.80", "1.20",
                "--augmentation_random_contrast", "0.80", "1.20",
                "--augmentation_random_saturation", "0.80", "1.20",
                "--augmentation_random_flip_type", "horizontal",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--checkpoint_dirpath", "/home/zfy/radar-camera-fusion-depth/checkpoints/Fusionnet",
                "--resultsave_dirpath", "trained_radar_camera_fusionnet_debug",
                "--n_step_per_checkpoint", "1",
                "--n_step_per_summary", "10",
                "--n_step_per_validation", "10",
                "--n_thread", "8",
                "--disc","debug",
                "--seed","355123027"
            ]
        },
        {
            "name": "Python: Train FusionNet with corrected radar",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/train_fusionnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "1"
            },
            "args": [
                //"--radar_camera_fusionnet_restore_path","/home/zfy/radar-camera-fusion-depth/trained_fusionnet_ablation/0604172806__Lfunc_l1_wdenseL_1.0_wlidarL_2.0_wpercepL_0.0_wsmoothness_0.0_fusiontype_gated_radar_SVFF_transfer_type_decoder_guidance_RGI_CBAM_concat_layers_[3, 4, 5, 6]_total_epoch_400--------svby_kdondanyrelaparam_intp_multilidar_GPU_2/model-140000.pth",
                "--train_image_path", "training/nuscenes_sub/nuscenes_train_dany_metric_predicted.txt",
                "--train_depth_path", "training/nuscenes_sub/nuscenes_train_depth_predicted.txt",
                "--train_response_path", "training/nuscenes_sub/nuscenes_train_response_predicted.txt",
                "--train_ground_truth_path", "training/nuscenes_sub/nuscenes_train_ground_truth_interp.txt",
                "--train_lidar_map_path", "training/nuscenes_sub/nuscenes_train_ground_truth.txt",
                // "--val_image_path", "validation/nuscenes_sub/nuscenes_val_image.txt",
                // "--val_depth_path", "validation/nuscenes_sub/nuscenes_val_radar_image.txt",
                // "--val_response_path", "validation/nuscenes_sub/nuscenes_val_response_predicted.txt",
                // "--val_ground_truth_path", "validation/nuscenes_sub/nuscenes_val_lidar.txt",
                "--val_image_path", "testing/nuscenes/nuscenes_test_dany_metric_predicted.txt",
                "--val_depth_path", "testing/nuscenes/nuscenes_test_output_depth.txt",
                "--val_response_path", "testing/nuscenes/nuscenes_test_output_response.txt",
                "--val_ground_truth_path", "testing/nuscenes/nuscenes_test_lidar.txt",
                "--batch_size", "16",
                "--n_height", "448",
                "--n_width", "448",
                "--input_channels_image", "1",
                "--input_channels_depth", "2",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "fusionnet18", "batch_norm",
                //"--frozen_strategy","conv.weight","norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                "--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                //"--n_filters_encoder_depth", "32", "64", "128", "256", "256", "256",
                "--fusion_type", "SVFF_add",
                "--guidance","RGI_CBAM_concat",
                "--guidance_layers","3","4","5","6",
                "--decoder_type", "multiscale", "batch_norm",
                "--output_type","metric_depth",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--learning_rates", "1e-4","1e-5",
                "--learning_schedule", "64","114",
                "--loss_func", "l1",
                "--w_smoothness", "0.0",
                "--w_lidar_loss", "2.0",
                "--w_dense_loss","1.0",
                "--w_perceptual_loss","0.0",
                "--w_weight_decay", "0.0",
                "--loss_smoothness_kernel_size", "-1",
                "--outlier_removal_kernel_size", "7",
                "--outlier_removal_threshold", "1.5",
                "--ground_truth_dilation_kernel_size", "-1",
                "--augmentation_probabilities", "1.00",
                "--augmentation_schedule", "-1",
                "--augmentation_random_crop_type", "horizontal", "vertical",
                "--augmentation_random_brightness", "0.80", "1.20",
                "--augmentation_random_contrast", "0.80", "1.20",
                "--augmentation_random_saturation", "0.80", "1.20",
                "--augmentation_random_flip_type", "horizontal",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--checkpoint_dirpath", "/home/zfy/radar-camera-fusion-depth/checkpoints/Fusionnet",
                "--resultsave_dirpath", "trained_radar_camera_fusionnet_debug",
                "--n_step_per_checkpoint", "5",
                "--n_step_per_summary", "1",
                "--n_step_per_validation", "10",
                "--n_thread", "8",
                "--disc","debug",
                "--seed","355123027"
            ]
        },
        {
            "name": "Python: Train StructralNet",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/src/train_structralnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "7"
            },
            "args": [
                //"--restore_path","trained_structralnet/0329160924_depth_loss_l1_w_depth_loss_1.0_w_grad_loss_1.0_w_ssim_loss_1.0_w_smoothness_0.0_multiscale_4_total_epoch_400_******_sobel_for_grad_ssimwin5_GPU_3",
                "--train_image_path", "training/nuscenes_sub/nuscenes_train_image.txt",
                "--train_ground_truth_path", "training/nuscenes_sub/nuscenes_train_dany_metric_predicted.txt",
                "--train_lidar_map_path", "training/nuscenes_sub/nuscenes_train_ground_truth.txt",
                "--val_image_path", "visl/path_txt/nuscenes/nuscenes_test_mini_image.txt",
                "--val_ground_truth_path", "visl/path_txt/nuscenes/nuscenes_test_mini_dany_metirc_predicted.txt",
                "--batch_size", "4",
                "--n_height", "448",
                "--n_width", "448",
                "--input_channels_image", "3",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "resnet18", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "256", "256", "256",
                "--n_filters_encoder_depth", "16", "32", "64", "128", "128", "128",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "256", "128", "64", "64", "32",
                "--n_resolutions_decoder", "1",
                "--min_predict_depth", "1.0",
                "--max_predict_depth", "80.0",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--learning_rates", "1e-3",
                "--learning_schedule", "20",
                "--loss_func", "l1",
                "--multiscale","1",
                "--w_smoothness", "0.0",
                "--w_depth_loss", "0.0",
                "--w_grad_loss","0.0",
                "--w_ssim_loss","0.0",
                "--w_perceptual_loss","1.0",
                "--w_weight_decay", "0.0",
                "--loss_smoothness_kernel_size", "-1",
                "--outlier_removal_kernel_size", "-1",
                "--outlier_removal_threshold", "1.5",
                "--ground_truth_dilation_kernel_size", "-1",
                "--augmentation_probabilities", "1.00",
                "--augmentation_schedule", "-1",
                "--augmentation_random_crop_type", "horizontal", "vertical",
                "--augmentation_random_brightness", "0.80", "1.20",
                "--augmentation_random_contrast", "0.80", "1.20",
                "--augmentation_random_saturation", "0.80", "1.20",
                "--augmentation_random_flip_type", "horizontal",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "80.0",
                //"--checkpoint_dirpath", "/home/zfy/radar-camera-fusion-depth/checkpoints/Fusionnet",
                "--resultsave_dirpath", "trained_structralnet",
                "--n_step_per_checkpoint", "10",
                "--n_step_per_summary", "5",
                "--n_step_per_validation", "10",
                "--n_thread", "8",
                "--disc","structral_student_model_debug",
                "--seed","355123027"
            ]
        },
        {
            "name": "Python: Setup Dataset Nuscenes Radarnet",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/setup/setup_dataset_nuscenes_radarnet.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                "--restore_path", "/home/zfy/radar-camera-fusion-depth/checkpoints/Radarnet/model-195000.pth",
                "--patch_size", "900", "288",
                "--input_channels_image", "3",
                "--input_channels_depth", "3",
                "--normalized_image_range", "0", "1",
                "--encoder_type", "radarnetv1", "batch_norm",
                "--n_filters_encoder_image", "32", "64", "128", "128", "128",
                "--n_neurons_encoder_depth", "32", "64", "128", "128", "128",
                "--decoder_type", "multiscale", "batch_norm",
                "--n_filters_decoder", "256", "128", "64", "32", "16",
                "--weight_initializer", "kaiming_uniform",
                "--activation_func", "leaky_relu",
                "--run_evaluation",
                "--min_evaluate_depth", "0.0",
                "--max_evaluate_depth", "100.0"
            ]
        },
        {
            "name": "Python Debugger: Global Alignment",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/tools/global_alignment.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            }
        },
        {
            "name": "Python Debugger: Global Alignment single token",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/tools/global_alignment_single_token.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            }
        }
    ]
}